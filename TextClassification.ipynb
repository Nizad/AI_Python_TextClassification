{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Izad\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Izad\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection._split import train_test_split\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from hazm import word_tokenize\n",
    "from hazm.Stemmer import Stemmer\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection.univariate_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics.classification import f1_score, precision_score, recall_score\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NewsID                                              Title  \\\n",
       "0  843656  \\nوزير علوم درجمع استادان نمونه: سن بازنشستگي ...   \n",
       "1  837144  \\nگردهمايي دانش‌آموختگان موسسه آموزش عالي سوره...   \n",
       "2  436862  \\nنتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور...   \n",
       "3  227781  \\nهمايش يكروزه آسيب شناسي مفهوم روابط عمومي در...   \n",
       "4  174187  \\nوضعيت اقتصادي و ميزان تحصيلات والدين از مهمت...   \n",
       "\n",
       "                                                Body         Date       Time  \\\n",
       "0  \\nوزير علوم در جمع استادان نمونه كشور گفت: از ...  \\n138/5//09  \\n0:9::18   \n",
       "1  \\nبه گزارش سرويس صنفي آموزشي خبرگزاري دانشجويا...  \\n138/5//09  \\n1:4::11   \n",
       "2  \\nنتايج آزمون دوره‌هاي فراگير مقاطع كارشناسي و...  \\n138/3//07  \\n1:0::03   \n",
       "3                                                 \\n  \\n138/2//02  \\n1:3::42   \n",
       "4  \\nمحمدتقي علوي يزدي، مجري اين طرح پژوهشي در اي...  \\n138/1//08  \\n1:1::49   \n",
       "\n",
       "             Category  Category2  \n",
       "0           \\nآموزشي-   \\nآموزشي  \n",
       "1           \\nآموزشي-   \\nآموزشي  \n",
       "2           \\nآموزشي-   \\nآموزشي  \n",
       "3  \\nاجتماعي-خانواده-  \\nاجتماعي  \n",
       "4           \\nآموزشي-   \\nآموزشي  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NewsID</th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Category</th>\n      <th>Category2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>843656</td>\n      <td>\\nوزير علوم درجمع استادان نمونه: سن بازنشستگي ...</td>\n      <td>\\nوزير علوم در جمع استادان نمونه كشور گفت: از ...</td>\n      <td>\\n138/5//09</td>\n      <td>\\n0:9::18</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>837144</td>\n      <td>\\nگردهمايي دانش‌آموختگان موسسه آموزش عالي سوره...</td>\n      <td>\\nبه گزارش سرويس صنفي آموزشي خبرگزاري دانشجويا...</td>\n      <td>\\n138/5//09</td>\n      <td>\\n1:4::11</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>436862</td>\n      <td>\\nنتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور...</td>\n      <td>\\nنتايج آزمون دوره‌هاي فراگير مقاطع كارشناسي و...</td>\n      <td>\\n138/3//07</td>\n      <td>\\n1:0::03</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>227781</td>\n      <td>\\nهمايش يكروزه آسيب شناسي مفهوم روابط عمومي در...</td>\n      <td>\\n</td>\n      <td>\\n138/2//02</td>\n      <td>\\n1:3::42</td>\n      <td>\\nاجتماعي-خانواده-</td>\n      <td>\\nاجتماعي</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174187</td>\n      <td>\\nوضعيت اقتصادي و ميزان تحصيلات والدين از مهمت...</td>\n      <td>\\nمحمدتقي علوي يزدي، مجري اين طرح پژوهشي در اي...</td>\n      <td>\\n138/1//08</td>\n      <td>\\n1:1::49</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "perisca_dataset = pd.read_csv(\"per.csv\", encoding=\"UTF-8\", header=0)\n",
    "perisca_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords from: https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian\n",
    "# NLTK : Natural Language Toolkit\n",
    "with open('stopwords.txt', encoding=\"UTF-8\") as stopwords_file:\n",
    "    stopwords = stopwords_file.readlines()\n",
    "stopwords = [str(line).replace('\\n', '') for line in stopwords]\n",
    "\n",
    "# insert NLTK English stopwords into nltk_stopwords\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "# appent presian stopwords in nltk_stopwords\n",
    "nltk_stopwords.extend(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1495"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer()\n",
    "dataset = pd.DataFrame(columns=('title_body', 'category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          title_body   category\n",
       "0  وزير علو درجمع استاد نمونه سن بازنشستگي استاد ...   \\nآموزشي\n",
       "1  گردهمايي دانش‌آموختگ موسسه آموز عالي سوره برگز...   \\nآموزشي\n",
       "2  نتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور ن...   \\nآموزشي\n",
       "3  هماي يكروزه آسيب شناسي مفهو روابط عمومي بابلسر...  \\nاجتماعي\n",
       "4  وضعي اقتصادي ميز تحصيل والدين مهمترين عوامل مو...   \\nآموزشي"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_body</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>وزير علو درجمع استاد نمونه سن بازنشستگي استاد ...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>گردهمايي دانش‌آموختگ موسسه آموز عالي سوره برگز...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>نتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور ن...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>هماي يكروزه آسيب شناسي مفهو روابط عمومي بابلسر...</td>\n      <td>\\nاجتماعي</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>وضعي اقتصادي ميز تحصيل والدين مهمترين عوامل مو...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# We can make a dataframe with the concatination of series\n",
    "for index, row in perisca_dataset.iterrows():\n",
    "    title_body = row['Title'] + ' ' + row['Body']\n",
    "    title_body_tokenized = word_tokenize(title_body)\n",
    "    title_body_tokenized_filtered = [w for w in title_body_tokenized if not w in nltk_stopwords]\n",
    "    title_body_tokenized_filtered_stemming = [stemmer.stem(w) for w in title_body_tokenized_filtered]\n",
    "    dataset.loc[index] = {'title_body': ' '.join(title_body_tokenized_filtered_stemming), 'category': row['Category2']}\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Document Frequency\n",
    "# idf=>  inverted doument frequency => 1/df\n",
    "# Tfidf =>  Tf * idf\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "X = vectorizer.fit(dataset['title_body']).transform(dataset['title_body']) # Bag of Words\n",
    "#--------------------------------------------\n",
    "# Why fit is separate from transform? \n",
    "# Fit only applys on training data, but transform would apply on both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['\\nآموزشي', '\\nاجتماعي', '\\nاقتصادي', '\\nبهداشتي', '\\nتاريخي',\n",
       "       '\\nسياسي', '\\nعلمي', '\\nفرهنگي', '\\nفقه و حقوق', '\\nمذهبي',\n",
       "       '\\nورزشي'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit(dataset['category']).transform(dataset['category'])\n",
    "numpy.unique(dataset['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10999, 60798)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "numpy.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10999,)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "numpy.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2 = SelectPercentile(chi2, 80)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDG score: 0.8585454545454545\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "score = sgd.score(X_test, y_test)\n",
    "print('SDG score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "svm score: 0.8472727272727273\n"
     ]
    }
   ],
   "source": [
    "svmc = svm.SVC()\n",
    "svmc.fit(X_train, y_train)\n",
    "score = svmc.score(X_test, y_test)\n",
    "print('svm score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "svm linear score: 0.854909090909091\n"
     ]
    }
   ],
   "source": [
    "svmlc = svm.SVC(kernel='linear')\n",
    "svmlc.fit(X_train, y_train)\n",
    "score = svmlc.score(X_test, y_test)\n",
    "print('svm linear score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "knn score: 0.8468905321857195\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "score = knn.score(X_train, y_train)\n",
    "print('knn score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn2 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "knn2.fit(X_train, y_train)\n",
    "score = knn2.score(X_train, y_train)\n",
    "print('knn2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnnb score: 0.8060370954055037\n"
     ]
    }
   ],
   "source": [
    "mnnb = MultinomialNB()\n",
    "mnnb.fit(X_train, y_train)\n",
    "score = mnnb.score(X_train, y_train)\n",
    "print('mnnb score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc score: 0.5729179294459934\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "score = abc.score(X_train, y_train)\n",
    "print('abc score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc2 score: 0.6158322220875257\n"
     ]
    }
   ],
   "source": [
    "abc2 = AdaBoostClassifier(n_estimators=100)\n",
    "abc2.fit(X_train, y_train)\n",
    "score = abc2.score(X_train, y_train)\n",
    "print('abc2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rfc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "score = rfc.score(X_train, y_train)\n",
    "print('rfc score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc2 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=200)\n",
    "rfc2.fit(X_train, y_train)\n",
    "score = rfc2.score(X_train, y_train)\n",
    "print('rfc2 score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcls score: 0.933567705176385\n"
     ]
    }
   ],
   "source": [
    "vcls = VotingClassifier(estimators=[('randomforest', rfc2), ('naivebayes', mnnb), ('knn', knn), ('svm', svmlc)])\n",
    "vcls.fit(X_train, y_train)\n",
    "score = vcls.score(X_train, y_train)\n",
    "print('vcls score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mlp score: 0.946781428051885\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), random_state=1, max_iter=1, warm_start=True)\n",
    "for i in range(10):\n",
    "    mlp.fit(X_train, y_train)\n",
    "score = mlp.score(X_train, y_train)\n",
    "print('mlp score: ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcls recal: 0.8117360851173391\n",
      "vcls precision: 0.8288885138354627\n",
      "vcls f1: 0.808676817701605\n",
      "vcls confusion matrix: \n",
      "[[243   1   0   0   2   0   2   1   0   0   0]\n",
      " [ 30 134  29   9  13   4   6  10   7   8   2]\n",
      " [  6  15 193   1   6   5   4   5   2   2   1]\n",
      " [  9   0   1 243   1   1   0   0   1   0   0]\n",
      " [  6   1   1   0 259   0   0   0   0   0   0]\n",
      " [  9   3   6   5  56 146   1   2  11   1   2]\n",
      " [ 32   4  10  34   3   4 159   1   1   0   3]\n",
      " [  8   7   5   0  27   3   4 194   0   6   2]\n",
      " [  4   8   2   2  16   8   1   0 203   0   0]\n",
      " [  1   4   3   1  11   2   0   1   2 226   0]\n",
      " [  0   0   1   3   1   1   1   0   0   0 235]]\n",
      "vcls zero one loss: 0.18727272727272726\n"
     ]
    }
   ],
   "source": [
    "vcls_predict = vcls.predict(X_test)\n",
    "vcls_recall = recall_score(y_test, vcls_predict, average='macro')\n",
    "vcls_precision = precision_score(y_test, vcls_predict, average='macro')\n",
    "vcls_f1 = f1_score(y_test, vcls_predict, average='macro')\n",
    "vcls_conf = confusion_matrix(y_test, vcls_predict)\n",
    "vcls_zol = zero_one_loss(y_test, vcls_predict)\n",
    "print(\"vcls recal: \" + str(vcls_recall))\n",
    "print(\"vcls precision: \" + str(vcls_precision))\n",
    "print(\"vcls f1: \" + str(vcls_f1))\n",
    "print(\"vcls confusion matrix: \\n\" + str(vcls_conf))\n",
    "print(\"vcls zero one loss: \" + str(vcls_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mlp recal: 0.8273488350112288\nmlp precision: 0.8225387422953303\nmlp f1: 0.8233802868428518\nmlp confusion matrix: \n[[211   4   3   3   1   2  17   1   1   2   0]\n [ 13 155  30  11   6  15   9  13   6   9   4]\n [  1  22 195   1   1  10   9   3   1   4   1]\n [  2   4   4 211   0   4   4   1   0   1   0]\n [  1   0   1   0 218   2   0   4   0   1   0]\n [  2   6  13   4  20 189   2   7  13   4   1]\n [ 17   5   7  19   1   4 189   5   1   1   0]\n [  1   9   3   2  10   4   7 199   0   4   2]\n [  1  17   2   1   8  11   7   2 211   4   1]\n [  0   6   1   0   1   2   2   1   1 245   0]\n [  1   4   0   2   1   0   0   2   0   1 242]]\nmlp zero one loss: 0.1763636363636364\n"
     ]
    }
   ],
   "source": [
    "mlp_predict = mlp.predict(X_test)\n",
    "mlp_recall = recall_score(y_test, mlp_predict, average='macro')\n",
    "mlp_precision = precision_score(y_test, mlp_predict, average='macro')\n",
    "mlp_f1 = f1_score(y_test, mlp_predict, average='macro')\n",
    "mlp_conf = confusion_matrix(y_test, mlp_predict)\n",
    "mlp_zol = zero_one_loss(y_test, mlp_predict)\n",
    "print(\"mlp recal: \" + str(mlp_recall))\n",
    "print(\"mlp precision: \" + str(mlp_precision))\n",
    "print(\"mlp f1: \" + str(mlp_f1))\n",
    "print(\"mlp confusion matrix: \\n\" + str(mlp_conf))\n",
    "print(\"mlp zero one loss: \" + str(mlp_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD recal: 0.8585117734456366\n",
      "SGD precision: 0.8559277325517001\n",
      "SGD f1: 0.8554769644173849\n",
      "SGD confusion matrix: \n",
      "[[227   5   2   2   0   2   7   3   0   1   0]\n",
      " [ 11 149  25   9   2  10   7  16   9  10   4]\n",
      " [  1  18 188   1   2  11   8   4   2   3   2]\n",
      " [  1   1   0 250   0   2   2   0   0   0   0]\n",
      " [  1   1   0   0 254   7   0   2   1   1   0]\n",
      " [  3   5   5   5  10 189   4   3  13   2   3]\n",
      " [ 18   3   7  22   1   4 187   5   1   0   3]\n",
      " [  2   7   1   0   5   3   3 227   1   5   2]\n",
      " [  1   4   3   1   3  12   3   1 216   0   0]\n",
      " [  0   4   3   0   1   3   0   1   0 239   0]\n",
      " [  0   1   1   3   0   0   0   0   0   0 237]]\n",
      "SGD zero one loss: 0.1407272727272727\n"
     ]
    }
   ],
   "source": [
    "sgd_predict = sgd.predict(X_test)\n",
    "sgd_recall = recall_score(y_test, sgd_predict, average='macro')\n",
    "sgd_precision = precision_score(y_test, sgd_predict, average='macro')\n",
    "sgd_f1 = f1_score(y_test, sgd_predict, average='macro')\n",
    "sgd_conf = confusion_matrix(y_test, sgd_predict)\n",
    "sgd_zol = zero_one_loss(y_test, sgd_predict)\n",
    "print(\"SGD recal: \" + str(sgd_recall))\n",
    "print(\"SGD precision: \" + str(sgd_precision))\n",
    "print(\"SGD f1: \" + str(sgd_f1))\n",
    "print(\"SGD confusion matrix: \\n\" + str(sgd_conf))\n",
    "print(\"SGD zero one loss: \" + str(sgd_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "svmc recal: 0.8506782054850516\nsvmc precision: 0.8463432486996034\nsvmc f1: 0.8471269563682576\nsvmc confusion matrix: \n[[223   5   0   3   0   2   7   1   2   2   0]\n [  8 172  25  11   6  13   6  13   4   9   4]\n [  2  20 197   0   1  11   8   3   1   4   1]\n [  1   4   1 223   0   0   2   0   0   0   0]\n [  1   1   1   0 215   3   1   4   1   0   0]\n [  4  11  15   5  11 181   4  10  16   3   1]\n [ 16  10   5  19   1   4 187   5   1   1   0]\n [  2   4   3   2   6   4   2 213   1   3   1]\n [  1  10   3   0   3   8   2   3 235   0   0]\n [  0   7   1   0   2   1   0   2   1 245   0]\n [  1   3   0   3   0   3   1   2   0   1 239]]\nsvmc zero one loss: 0.1527272727272727\n"
     ]
    }
   ],
   "source": [
    "svmc_predict = svmc.predict(X_test)\n",
    "svmc_recall = recall_score(y_test, svmc_predict, average='macro')\n",
    "svmc_precision = precision_score(y_test, svmc_predict, average='macro')\n",
    "svmc_f1 = f1_score(y_test, svmc_predict, average='macro')\n",
    "svmc_conf = confusion_matrix(y_test, svmc_predict)\n",
    "svmc_zol = zero_one_loss(y_test, svmc_predict)\n",
    "print(\"svmc recal: \" + str(svmc_recall))\n",
    "print(\"svmc precision: \" + str(svmc_precision))\n",
    "print(\"svmc f1: \" + str(svmc_f1))\n",
    "print(\"svmc confusion matrix: \\n\" + str(svmc_conf))\n",
    "print(\"svmc zero one loss: \" + str(svmc_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmlc recal: 0.8509185051143775\n",
      "svmlc precision: 0.8504678195822618\n",
      "svmlc f1: 0.8499912463562375\n",
      "svmlc confusion matrix: \n",
      "[[224   7   0   1   0   1  13   3   0   0   0]\n",
      " [ 16 156  24   8   2  11   9  15   4   6   1]\n",
      " [  0  25 185   1   0   9   8   7   2   2   1]\n",
      " [  2   2   0 247   0   2   2   0   0   0   1]\n",
      " [  4   3   0   0 251   7   0   1   1   0   0]\n",
      " [  4   8   5   5  10 191   3   2  10   2   2]\n",
      " [ 17   5   7  19   0   5 193   2   1   0   2]\n",
      " [  5  13   2   0   3   5   4 217   0   6   1]\n",
      " [  0  10   2   1   3  14   3   1 210   0   0]\n",
      " [  0   5   3   1   0   5   0   1   2 234   0]\n",
      " [  0   1   1   3   0   2   1   0   0   0 234]]\n",
      "svmlc zero one loss: 0.14836363636363636\n"
     ]
    }
   ],
   "source": [
    "svmlc_predict = svmlc.predict(X_test)\n",
    "svmlc_recall = recall_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_precision = precision_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_f1 = f1_score(y_test, svmlc_predict, average='macro')\n",
    "svmlc_conf = confusion_matrix(y_test, svmlc_predict)\n",
    "svmlc_zol = zero_one_loss(y_test, svmlc_predict)\n",
    "print(\"svmlc recal: \" + str(svmlc_recall))\n",
    "print(\"svmlc precision: \" + str(svmlc_precision))\n",
    "print(\"svmlc f1: \" + str(svmlc_f1))\n",
    "print(\"svmlc confusion matrix: \\n\" + str(svmlc_conf))\n",
    "print(\"svmlc zero one loss: \" + str(svmlc_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn recal: 0.7634691471480437\n",
      "knn precision: 0.7802196882009302\n",
      "knn f1: 0.7609107391421331\n",
      "svmlc confusion matrix: \n",
      "[[229   5   1   3   4   1   4   1   0   0   1]\n",
      " [ 24 134  20   9  18  10   9   6   7  11   4]\n",
      " [  6  24 174   2  10   8   7   3   1   4   1]\n",
      " [ 13   5   4 227   2   0   1   2   2   0   0]\n",
      " [  6   2   1   0 254   2   0   0   2   0   0]\n",
      " [ 12  13   9   4  60 130   2   0   9   1   2]\n",
      " [ 32  11  17  31   5   8 141   3   1   0   2]\n",
      " [  6  10  14   1  27  10   5 171   0  10   2]\n",
      " [  5  12   3   5  20   9   3   1 186   0   0]\n",
      " [  1   2   6   0  11   1   0   0   1 229   0]\n",
      " [  2   0   2   2   4   3   0   1   0   0 228]]\n",
      "svmlc zero one loss: 0.2352727272727273\n"
     ]
    }
   ],
   "source": [
    "knn_predict = knn.predict(X_test)\n",
    "knn_recall = recall_score(y_test, knn_predict, average='macro')\n",
    "knn_precision = precision_score(y_test, knn_predict, average='macro')\n",
    "knn_f1 = f1_score(y_test, knn_predict, average='macro')\n",
    "knn_conf = confusion_matrix(y_test, knn_predict)\n",
    "knn_zol = zero_one_loss(y_test, knn_predict)\n",
    "print(\"knn recal: \" + str(knn_recall))\n",
    "print(\"knn precision: \" + str(knn_precision))\n",
    "print(\"knn f1: \" + str(knn_f1))\n",
    "print(\"svmlc confusion matrix: \\n\" + str(knn_conf))\n",
    "print(\"svmlc zero one loss: \" + str(knn_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn2 recal: 0.7810959710663937\n",
      "knn2 precision: 0.8010217840054714\n",
      "knn2 f1: 0.7754818983688608\n",
      "knn2 confusion matrix: \n",
      "[[236   3   0   3   3   0   0   3   0   1   0]\n",
      " [ 26 108  25  13  28   6   9   6  13  13   5]\n",
      " [  5  15 177   3  10   7   8   3   3   8   1]\n",
      " [ 10   1   2 237   4   0   1   1   0   0   0]\n",
      " [  3   1   0   0 259   2   0   1   1   0   0]\n",
      " [  6   4   6   5  70 127   3   1  12   4   4]\n",
      " [ 32   6   9  34  12   3 151   1   1   0   2]\n",
      " [  6   5   2   1  26   5   3 193   1  12   2]\n",
      " [  4   6   4   5  20   6   2   1 195   1   0]\n",
      " [  1   0   3   0   9   0   0   1   0 237   0]\n",
      " [  0   0   1   3   3   1   0   1   1   0 232]]\n",
      "knn2 zero one loss: 0.21745454545454546\n"
     ]
    }
   ],
   "source": [
    "knn2_predict = knn2.predict(X_test)\n",
    "knn2_recall = recall_score(y_test, knn2_predict, average='macro')\n",
    "knn2_precision = precision_score(y_test, knn2_predict, average='macro')\n",
    "knn2_f1 = f1_score(y_test, knn2_predict, average='macro')\n",
    "knn2_conf = confusion_matrix(y_test, knn2_predict)\n",
    "knn2_zol = zero_one_loss(y_test, knn2_predict)\n",
    "print(\"knn2 recal: \" + str(knn2_recall))\n",
    "print(\"knn2 precision: \" + str(knn2_precision))\n",
    "print(\"knn2 f1: \" + str(knn2_f1))\n",
    "print(\"knn2 confusion matrix: \\n\" + str(knn2_conf))\n",
    "print(\"knn2 zero one loss: \" + str(knn2_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnnb recal: 0.7209294343471309\n",
      "mnnb precision: 0.785554197645527\n",
      "mnnb f1: 0.7172835633860047\n",
      "mnnb confusion matrix: \n",
      "[[231   1   0   2  11   0   3   0   1   0   0]\n",
      " [ 32  64  54  10  50   5   6   7  15   9   0]\n",
      " [  7   7 181   2  23   4   3   2   3   7   1]\n",
      " [ 17   1   1 230   4   1   0   0   1   0   1]\n",
      " [  4   0   0   0 261   0   0   0   2   0   0]\n",
      " [  4   0   5   5  99 118   1   1   9   0   0]\n",
      " [ 36   3  15  35  13   3 138   1   3   0   4]\n",
      " [ 10   6   4   0  73   1   4 145   2   9   2]\n",
      " [  4   2   5   2  49   3   2   0 175   2   0]\n",
      " [  1   2   1   1  20   0   0   1   1 224   0]\n",
      " [  3   0   3   4  10   0   1   0   2   0 219]]\n",
      "mnnb zero one loss: 0.27781818181818185\n"
     ]
    }
   ],
   "source": [
    "mnnb_predict = mnnb.predict(X_test)\n",
    "mnnb_recall = recall_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_precision = precision_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_f1 = f1_score(y_test, mnnb_predict, average='macro')\n",
    "mnnb_conf = confusion_matrix(y_test, mnnb_predict)\n",
    "mnnb_zol = zero_one_loss(y_test, mnnb_predict)\n",
    "print(\"mnnb recal: \" + str(mnnb_recall))\n",
    "print(\"mnnb precision: \" + str(mnnb_precision))\n",
    "print(\"mnnb f1: \" + str(mnnb_f1))\n",
    "print(\"mnnb confusion matrix: \\n\" + str(mnnb_conf))\n",
    "print(\"mnnb zero one loss: \" + str(mnnb_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc recal: 0.5574905902693778\n",
      "abc precision: 0.5552256041942149\n",
      "abc f1: 0.5370214080066794\n",
      "abc confusion matrix: \n",
      "[[196   9   2   2   2   1  30   4   1   2   0]\n",
      " [ 18  26 127  11  10   8  29   3   7  10   3]\n",
      " [  1  20 171   7   4   4  11   4  12   4   2]\n",
      " [  3   8   7 209   1   1  25   0   0   1   1]\n",
      " [  3   1  13   0 194  16   9  18   9   4   0]\n",
      " [  4  14 125   7  13  18  16  12  22   7   4]\n",
      " [ 14   7  33  21   2   1 155  11   3   0   4]\n",
      " [  1  19 119   1  32   8  35  19   6  10   6]\n",
      " [  1   8  20   6  10  17   5   4 168   5   0]\n",
      " [  0   9  36   0  10   6   4  10   1 175   0]\n",
      " [  2   1  25   4   0   2   0   4   0   2 202]]\n",
      "abc zero one loss: 0.4425454545454546\n"
     ]
    }
   ],
   "source": [
    "abc_predict = abc.predict(X_test)\n",
    "abc_recall = recall_score(y_test, abc_predict, average='macro')\n",
    "abc_precision = precision_score(y_test, abc_predict, average='macro')\n",
    "abc_f1 = f1_score(y_test, abc_predict, average='macro')\n",
    "abc_conf = confusion_matrix(y_test, abc_predict)\n",
    "abc_zol = zero_one_loss(y_test, abc_predict)\n",
    "print(\"abc recal: \" + str(abc_recall))\n",
    "print(\"abc precision: \" + str(abc_precision))\n",
    "print(\"abc f1: \" + str(abc_f1))\n",
    "print(\"abc confusion matrix: \\n\" + str(abc_conf))\n",
    "print(\"abc zero one loss: \" + str(abc_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc2 recal: 0.5786762578583496\n",
      "abc2 precision: 0.5979905340864783\n",
      "abc2 f1: 0.5800551554649136\n",
      "abc2 confusion matrix: \n",
      "[[196  10   1   8   0   1  26   4   2   1   0]\n",
      " [ 18  36  36   4  11  88  28  14   6   7   4]\n",
      " [  1  23  59   4   5 114  15   5  10   4   0]\n",
      " [  2   9  10 213   1   7  13   1   0   0   0]\n",
      " [  4   5   4   2 194  20   8  17   9   4   0]\n",
      " [  2  17  17   6  18 123  17   8  19   7   8]\n",
      " [ 17  15  18  20   2  15 148  10   3   1   2]\n",
      " [  3  22  12   0  16  74  25  79   5  14   6]\n",
      " [  1  11   6   6  11  25   4   5 171   4   0]\n",
      " [  0  11  11   0  11  30   2   9   2 175   0]\n",
      " [  2   8   4   0   0  12   5  10   0   1 200]]\n",
      "abc2 zero one loss: 0.4203636363636364\n"
     ]
    }
   ],
   "source": [
    "abc2_predict = abc2.predict(X_test)\n",
    "abc2_recall = recall_score(y_test, abc2_predict, average='macro')\n",
    "abc2_precision = precision_score(y_test, abc2_predict, average='macro')\n",
    "abc2_f1 = f1_score(y_test, abc2_predict, average='macro')\n",
    "abc2_conf = confusion_matrix(y_test, abc2_predict)\n",
    "abc2_zol = zero_one_loss(y_test, abc2_predict)\n",
    "print(\"abc2 recal: \" + str(abc2_recall))\n",
    "print(\"abc2 precision: \" + str(abc2_precision))\n",
    "print(\"abc2 f1: \" + str(abc2_f1))\n",
    "print(\"abc2 confusion matrix: \\n\" + str(abc2_conf))\n",
    "print(\"abc2 zero one loss: \" + str(abc2_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc recal: 0.6935644529527795\n",
      "rfc precision: 0.6949155294001851\n",
      "rfc f1: 0.6904362568910011\n",
      "rfc confusion matrix: \n",
      "[[207   6   1   8   1   0  22   2   1   1   0]\n",
      " [ 27  86  45  18   9  15  12  17  13   9   1]\n",
      " [ 11  37 141   8   4  13  11   9   3   2   1]\n",
      " [  6   2   6 232   0   2   6   0   1   0   1]\n",
      " [  4  10   3   3 217  16   2   4   3   5   0]\n",
      " [ 13  15  10   3  30 139   6   6  15   3   2]\n",
      " [ 35  14  20  31   1   5 135   8   0   0   2]\n",
      " [ 13  15   6   2  11  11  12 173   2   5   6]\n",
      " [  3  21   9   7  13  17   9   2 159   3   1]\n",
      " [  1  16   4   2  12   8   1   6   3 197   1]\n",
      " [  3   2   1   5   3   2   0   2   0   0 224]]\n",
      "rfc zero one loss: 0.3054545454545454\n"
     ]
    }
   ],
   "source": [
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_recall = recall_score(y_test, rfc_predict, average='macro')\n",
    "rfc_precision = precision_score(y_test, rfc_predict, average='macro')\n",
    "rfc_f1 = f1_score(y_test, rfc_predict, average='macro')\n",
    "rfc_conf = confusion_matrix(y_test, rfc_predict)\n",
    "rfc_zol = zero_one_loss(y_test, rfc_predict)\n",
    "print(\"rfc recal: \" + str(rfc_recall))\n",
    "print(\"rfc precision: \" + str(rfc_precision))\n",
    "print(\"rfc f1: \" + str(rfc_f1))\n",
    "print(\"rfc confusion matrix: \\n\" + str(rfc_conf))\n",
    "print(\"rfc zero one loss: \" + str(rfc_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'rfc2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-57dc12ef5c47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfc2_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrfc2_recall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc2_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrfc2_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc2_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrfc2_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc2_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrfc2_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc2_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rfc2' is not defined"
     ]
    }
   ],
   "source": [
    "rfc2_predict = rfc2.predict(X_test)\n",
    "rfc2_recall = recall_score(y_test, rfc2_predict, average='macro')\n",
    "rfc2_precision = precision_score(y_test, rfc2_predict, average='macro')\n",
    "rfc2_f1 = f1_score(y_test, rfc2_predict, average='macro')\n",
    "rfc2_conf = confusion_matrix(y_test, rfc2_predict)\n",
    "rfc2_zol = zero_one_loss(y_test, rfc2_predict)\n",
    "print(\"rfc2 recal: \" + str(rfc2_recall))\n",
    "print(\"rfc2 precision: \" + str(rfc2_precision))\n",
    "print(\"rfc2 f1: \" + str(rfc2_f1))\n",
    "print(\"rfc2 confusion matrix: \\n\" + str(rfc2_conf))\n",
    "print(\"rfc2 zero one loss: \" + str(rfc2_zol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 200)               12159800  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 200)               40200     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 200)               40200     \n_________________________________________________________________\ndense_4 (Dense)              (None, 11)                2211      \n=================================================================\nTotal params: 12,242,411\nTrainable params: 12,242,411\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KX_train, KX_test, Ky_train, Ky_test = train_test_split(X, to_categorical(y, 11))\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(200, activation=\"relu\", input_shape=(60798,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(200, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(200, activation=\"relu\"))\n",
    "model.add(layers.Dense(11, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8249 samples, validate on 2750 samples\n",
      "Epoch 1/5\n",
      "8249/8249 [==============================] - 20s 2ms/step - loss: 0.5457 - accuracy: 0.8856 - val_loss: 0.3330 - val_accuracy: 0.9091\n",
      "Epoch 2/5\n",
      "8249/8249 [==============================] - 17s 2ms/step - loss: 0.3395 - accuracy: 0.9091 - val_loss: 0.3274 - val_accuracy: 0.9091\n",
      "Epoch 3/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.3109 - accuracy: 0.9091 - val_loss: 0.2982 - val_accuracy: 0.9091\n",
      "Epoch 4/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.2835 - accuracy: 0.9092 - val_loss: 0.2604 - val_accuracy: 0.9107\n",
      "Epoch 5/5\n",
      "8249/8249 [==============================] - 15s 2ms/step - loss: 0.2302 - accuracy: 0.9172 - val_loss: 0.1937 - val_accuracy: 0.9293\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-8a91c22380eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKy_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Deep acc: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "results = model.fit(KX_train, Ky_train, epochs=5, batch_size=500, validation_data=(KX_test, Ky_test))\n",
    "print(\"Deep acc: \", numpy.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 500)               30399500  \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 150)               75150     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 150)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 100)               15100     \n_________________________________________________________________\ndense_8 (Dense)              (None, 11)                1111      \n=================================================================\nTotal params: 30,490,861\nTrainable params: 30,490,861\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KX_train, KX_test, Ky_train, Ky_test = train_test_split(X, to_categorical(y, 11))\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(500, activation=\"relu\", input_shape=(60798,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(150, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(100, activation=\"relu\"))\n",
    "model.add(layers.Dense(11, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8249 samples, validate on 2750 samples\n",
      "Epoch 1/5\n",
      "8249/8249 [==============================] - 32s 4ms/step - loss: 0.5241 - accuracy: 0.8803 - val_loss: 0.3458 - val_accuracy: 0.9091\n",
      "Epoch 2/5\n",
      "8249/8249 [==============================] - 33s 4ms/step - loss: 0.3349 - accuracy: 0.9091 - val_loss: 0.3139 - val_accuracy: 0.9091\n",
      "Epoch 3/5\n",
      "8249/8249 [==============================] - 31s 4ms/step - loss: 0.2916 - accuracy: 0.9093 - val_loss: 0.2641 - val_accuracy: 0.9115\n",
      "Epoch 4/5\n",
      "8249/8249 [==============================] - 27s 3ms/step - loss: 0.2401 - accuracy: 0.9138 - val_loss: 0.2091 - val_accuracy: 0.9180\n",
      "Epoch 5/5\n",
      "8249/8249 [==============================] - 29s 3ms/step - loss: 0.1741 - accuracy: 0.9342 - val_loss: 0.1489 - val_accuracy: 0.9446\n",
      "Deep acc:  0.918439757823944\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "results = model.fit(KX_train, Ky_train, epochs=5, batch_size=500, validation_data=(KX_test, Ky_test))\n",
    "print(\"Deep acc: \", numpy.mean(results.history[\"val_accuracy\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "988412709a56089a17f973023b68eccd46d4a32961ad6097527312ccb41cd289"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}