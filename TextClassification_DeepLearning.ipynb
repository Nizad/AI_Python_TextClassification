{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Izad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Izad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection._split import train_test_split\n",
    "# from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from hazm import word_tokenize\n",
    "from hazm.Stemmer import Stemmer\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection.univariate_selection import SelectPercentile\n",
    "# from sklearn.feature_selection import chi2\n",
    "import numpy\n",
    "# from sklearn import svm\n",
    "# from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "# from sklearn.ensemble.forest import RandomForestClassifier\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics.classification import f1_score, precision_score, recall_score\n",
    "# from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NewsID                                              Title  \\\n",
       "0  843656  \\nوزير علوم درجمع استادان نمونه: سن بازنشستگي ...   \n",
       "1  837144  \\nگردهمايي دانش‌آموختگان موسسه آموزش عالي سوره...   \n",
       "2  436862  \\nنتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور...   \n",
       "3  227781  \\nهمايش يكروزه آسيب شناسي مفهوم روابط عمومي در...   \n",
       "4  174187  \\nوضعيت اقتصادي و ميزان تحصيلات والدين از مهمت...   \n",
       "\n",
       "                                                Body         Date       Time  \\\n",
       "0  \\nوزير علوم در جمع استادان نمونه كشور گفت: از ...  \\n138/5//09  \\n0:9::18   \n",
       "1  \\nبه گزارش سرويس صنفي آموزشي خبرگزاري دانشجويا...  \\n138/5//09  \\n1:4::11   \n",
       "2  \\nنتايج آزمون دوره‌هاي فراگير مقاطع كارشناسي و...  \\n138/3//07  \\n1:0::03   \n",
       "3                                                 \\n  \\n138/2//02  \\n1:3::42   \n",
       "4  \\nمحمدتقي علوي يزدي، مجري اين طرح پژوهشي در اي...  \\n138/1//08  \\n1:1::49   \n",
       "\n",
       "             Category  Category2  \n",
       "0           \\nآموزشي-   \\nآموزشي  \n",
       "1           \\nآموزشي-   \\nآموزشي  \n",
       "2           \\nآموزشي-   \\nآموزشي  \n",
       "3  \\nاجتماعي-خانواده-  \\nاجتماعي  \n",
       "4           \\nآموزشي-   \\nآموزشي  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NewsID</th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Category</th>\n      <th>Category2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>843656</td>\n      <td>\\nوزير علوم درجمع استادان نمونه: سن بازنشستگي ...</td>\n      <td>\\nوزير علوم در جمع استادان نمونه كشور گفت: از ...</td>\n      <td>\\n138/5//09</td>\n      <td>\\n0:9::18</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>837144</td>\n      <td>\\nگردهمايي دانش‌آموختگان موسسه آموزش عالي سوره...</td>\n      <td>\\nبه گزارش سرويس صنفي آموزشي خبرگزاري دانشجويا...</td>\n      <td>\\n138/5//09</td>\n      <td>\\n1:4::11</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>436862</td>\n      <td>\\nنتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور...</td>\n      <td>\\nنتايج آزمون دوره‌هاي فراگير مقاطع كارشناسي و...</td>\n      <td>\\n138/3//07</td>\n      <td>\\n1:0::03</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>227781</td>\n      <td>\\nهمايش يكروزه آسيب شناسي مفهوم روابط عمومي در...</td>\n      <td>\\n</td>\n      <td>\\n138/2//02</td>\n      <td>\\n1:3::42</td>\n      <td>\\nاجتماعي-خانواده-</td>\n      <td>\\nاجتماعي</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174187</td>\n      <td>\\nوضعيت اقتصادي و ميزان تحصيلات والدين از مهمت...</td>\n      <td>\\nمحمدتقي علوي يزدي، مجري اين طرح پژوهشي در اي...</td>\n      <td>\\n138/1//08</td>\n      <td>\\n1:1::49</td>\n      <td>\\nآموزشي-</td>\n      <td>\\nآموزشي</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "perisca_dataset = pd.read_csv(\"per.csv\", encoding=\"UTF-8\", header=0)\n",
    "perisca_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords from: https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian\n",
    "# NLTK : Natural Language Toolkit\n",
    "with open('stopwords.txt', encoding=\"UTF-8\") as stopwords_file:\n",
    "    stopwords = stopwords_file.readlines()\n",
    "stopwords = [str(line).replace('\\n', '') for line in stopwords]\n",
    "\n",
    "# insert NLTK English stopwords into nltk_stopwords\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "# appent presian stopwords in nltk_stopwords\n",
    "nltk_stopwords.extend(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1495"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer()\n",
    "dataset = pd.DataFrame(columns=('title_body', 'category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          title_body   category\n",
       "0  وزير علو درجمع استاد نمونه سن بازنشستگي استاد ...   \\nآموزشي\n",
       "1  گردهمايي دانش‌آموختگ موسسه آموز عالي سوره برگز...   \\nآموزشي\n",
       "2  نتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور ن...   \\nآموزشي\n",
       "3  هماي يكروزه آسيب شناسي مفهو روابط عمومي بابلسر...  \\nاجتماعي\n",
       "4  وضعي اقتصادي ميز تحصيل والدين مهمترين عوامل مو...   \\nآموزشي"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_body</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>وزير علو درجمع استاد نمونه سن بازنشستگي استاد ...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>گردهمايي دانش‌آموختگ موسسه آموز عالي سوره برگز...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>نتايج آزمون دوره‌هاي فراگير دانشگاه پيام‌نور ن...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>هماي يكروزه آسيب شناسي مفهو روابط عمومي بابلسر...</td>\n      <td>\\nاجتماعي</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>وضعي اقتصادي ميز تحصيل والدين مهمترين عوامل مو...</td>\n      <td>\\nآموزشي</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# We can make a dataframe with the concatination of series\n",
    "for index, row in perisca_dataset.iterrows():\n",
    "    title_body = row['Title'] + ' ' + row['Body']\n",
    "    title_body_tokenized = word_tokenize(title_body)\n",
    "    title_body_tokenized_filtered = [w for w in title_body_tokenized if not w in nltk_stopwords]\n",
    "    title_body_tokenized_filtered_stemming = [stemmer.stem(w) for w in title_body_tokenized_filtered]\n",
    "    dataset.loc[index] = {'title_body': ' '.join(title_body_tokenized_filtered_stemming), 'category': row['Category2']}\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Document Frequency\n",
    "# idf=>  inverted doument frequency => 1/df\n",
    "# Tfidf =>  Tf * idf\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "X = vectorizer.fit(dataset['title_body']).transform(dataset['title_body']) # Bag of Words\n",
    "#--------------------------------------------\n",
    "# Why fit is separate from transform? \n",
    "# Fit only applys on training data, but transform would apply on both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['\\nآموزشي', '\\nاجتماعي', '\\nاقتصادي', '\\nبهداشتي', '\\nتاريخي',\n",
       "       '\\nسياسي', '\\nعلمي', '\\nفرهنگي', '\\nفقه و حقوق', '\\nمذهبي',\n",
       "       '\\nورزشي'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit(dataset['category']).transform(dataset['category'])\n",
    "numpy.unique(dataset['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10999, 60798)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "numpy.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10999,)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "numpy.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 200)               12159800  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 200)               40200     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 200)               40200     \n_________________________________________________________________\ndense_4 (Dense)              (None, 11)                2211      \n=================================================================\nTotal params: 12,242,411\nTrainable params: 12,242,411\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KX_train, KX_test, Ky_train, Ky_test = train_test_split(X, to_categorical(y, 11))\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(200, activation=\"relu\", input_shape=(60798,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(200, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(200, activation=\"relu\"))\n",
    "model.add(layers.Dense(11, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8249 samples, validate on 2750 samples\n",
      "Epoch 1/5\n",
      "8249/8249 [==============================] - 17s 2ms/step - loss: 0.5283 - accuracy: 0.8932 - val_loss: 0.3513 - val_accuracy: 0.9091\n",
      "Epoch 2/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.3362 - accuracy: 0.9091 - val_loss: 0.3196 - val_accuracy: 0.9091\n",
      "Epoch 3/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.3026 - accuracy: 0.9091 - val_loss: 0.2849 - val_accuracy: 0.9091\n",
      "Epoch 4/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.2598 - accuracy: 0.9107 - val_loss: 0.2237 - val_accuracy: 0.9187\n",
      "Epoch 5/5\n",
      "8249/8249 [==============================] - 16s 2ms/step - loss: 0.1817 - accuracy: 0.9291 - val_loss: 0.1480 - val_accuracy: 0.9448\n",
      "Deep acc:  0.9181554913520813\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "results = model.fit(KX_train, Ky_train, epochs=5, batch_size=500, validation_data=(KX_test, Ky_test))\n",
    "print(\"Deep acc: \", numpy.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 500)               30399500  \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 150)               75150     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 150)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 100)               15100     \n_________________________________________________________________\ndense_8 (Dense)              (None, 11)                1111      \n=================================================================\nTotal params: 30,490,861\nTrainable params: 30,490,861\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KX_train, KX_test, Ky_train, Ky_test = train_test_split(X, to_categorical(y, 11))\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(500, activation=\"relu\", input_shape=(60798,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(150, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(100, activation=\"relu\"))\n",
    "model.add(layers.Dense(11, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8249 samples, validate on 2750 samples\n",
      "Epoch 1/5\n",
      "8249/8249 [==============================] - 32s 4ms/step - loss: 0.5241 - accuracy: 0.8803 - val_loss: 0.3458 - val_accuracy: 0.9091\n",
      "Epoch 2/5\n",
      "8249/8249 [==============================] - 33s 4ms/step - loss: 0.3349 - accuracy: 0.9091 - val_loss: 0.3139 - val_accuracy: 0.9091\n",
      "Epoch 3/5\n",
      "8249/8249 [==============================] - 31s 4ms/step - loss: 0.2916 - accuracy: 0.9093 - val_loss: 0.2641 - val_accuracy: 0.9115\n",
      "Epoch 4/5\n",
      "8249/8249 [==============================] - 27s 3ms/step - loss: 0.2401 - accuracy: 0.9138 - val_loss: 0.2091 - val_accuracy: 0.9180\n",
      "Epoch 5/5\n",
      "8249/8249 [==============================] - 29s 3ms/step - loss: 0.1741 - accuracy: 0.9342 - val_loss: 0.1489 - val_accuracy: 0.9446\n",
      "Deep acc:  0.918439757823944\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "results = model.fit(KX_train, Ky_train, epochs=5, batch_size=500, validation_data=(KX_test, Ky_test))\n",
    "print(\"Deep acc: \", numpy.mean(results.history[\"val_accuracy\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "988412709a56089a17f973023b68eccd46d4a32961ad6097527312ccb41cd289"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}